{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "credit_card_data = pd.read_csv('D:/Final Year Project/Credit Card Fraud Detection/archive/creditcard.csv')\n",
    "credit_card_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# dataset informations\n",
    "credit_card_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the number of missing values in each column\n",
    "credit_card_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card_data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = credit_card_data[credit_card_data.Class == 0]\n",
    "fraud = credit_card_data[credit_card_data.Class == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284315, 31)\n",
      "(492, 31)\n"
     ]
    }
   ],
   "source": [
    "print(legit.shape)\n",
    "print(fraud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legit.Amount.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.Amount.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "legit_sample = legit.sample(n=492)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.concat([legit_sample, fraud], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49186</th>\n",
       "      <td>43950.0</td>\n",
       "      <td>-0.394463</td>\n",
       "      <td>0.036658</td>\n",
       "      <td>0.404250</td>\n",
       "      <td>-1.770945</td>\n",
       "      <td>-0.165441</td>\n",
       "      <td>-0.076140</td>\n",
       "      <td>0.938138</td>\n",
       "      <td>-0.220247</td>\n",
       "      <td>-1.522497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275536</td>\n",
       "      <td>-0.252815</td>\n",
       "      <td>-0.037271</td>\n",
       "      <td>-0.433363</td>\n",
       "      <td>-0.534420</td>\n",
       "      <td>0.827410</td>\n",
       "      <td>-0.003107</td>\n",
       "      <td>0.143291</td>\n",
       "      <td>125.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148622</th>\n",
       "      <td>90083.0</td>\n",
       "      <td>-0.348459</td>\n",
       "      <td>0.641847</td>\n",
       "      <td>0.845793</td>\n",
       "      <td>-0.101879</td>\n",
       "      <td>0.890992</td>\n",
       "      <td>-1.039237</td>\n",
       "      <td>1.103789</td>\n",
       "      <td>-0.609933</td>\n",
       "      <td>1.116355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.377947</td>\n",
       "      <td>-0.514977</td>\n",
       "      <td>0.292790</td>\n",
       "      <td>-0.003732</td>\n",
       "      <td>-0.763451</td>\n",
       "      <td>0.112490</td>\n",
       "      <td>-0.148373</td>\n",
       "      <td>-0.079387</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33146</th>\n",
       "      <td>37108.0</td>\n",
       "      <td>-0.841910</td>\n",
       "      <td>0.427966</td>\n",
       "      <td>1.330937</td>\n",
       "      <td>0.301196</td>\n",
       "      <td>0.609865</td>\n",
       "      <td>-0.219677</td>\n",
       "      <td>0.900994</td>\n",
       "      <td>0.060344</td>\n",
       "      <td>-0.531687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083133</td>\n",
       "      <td>0.150999</td>\n",
       "      <td>-0.050524</td>\n",
       "      <td>0.013978</td>\n",
       "      <td>0.142768</td>\n",
       "      <td>-0.543907</td>\n",
       "      <td>0.092772</td>\n",
       "      <td>0.136472</td>\n",
       "      <td>77.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264977</th>\n",
       "      <td>161676.0</td>\n",
       "      <td>-2.095268</td>\n",
       "      <td>-0.113154</td>\n",
       "      <td>0.839074</td>\n",
       "      <td>-1.434403</td>\n",
       "      <td>-0.665841</td>\n",
       "      <td>-0.353520</td>\n",
       "      <td>-0.428983</td>\n",
       "      <td>0.858931</td>\n",
       "      <td>-1.274300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533818</td>\n",
       "      <td>-1.636550</td>\n",
       "      <td>-0.234419</td>\n",
       "      <td>-0.722215</td>\n",
       "      <td>0.257054</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>-0.303029</td>\n",
       "      <td>-0.230370</td>\n",
       "      <td>80.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93587</th>\n",
       "      <td>64497.0</td>\n",
       "      <td>-3.141003</td>\n",
       "      <td>-0.036423</td>\n",
       "      <td>0.856031</td>\n",
       "      <td>1.320876</td>\n",
       "      <td>-1.720489</td>\n",
       "      <td>0.500438</td>\n",
       "      <td>-0.410874</td>\n",
       "      <td>1.402324</td>\n",
       "      <td>-0.624236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154052</td>\n",
       "      <td>0.234413</td>\n",
       "      <td>0.182089</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>0.358644</td>\n",
       "      <td>-0.271475</td>\n",
       "      <td>-0.220354</td>\n",
       "      <td>-0.604723</td>\n",
       "      <td>141.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "49186    43950.0 -0.394463  0.036658  0.404250 -1.770945 -0.165441 -0.076140   \n",
       "148622   90083.0 -0.348459  0.641847  0.845793 -0.101879  0.890992 -1.039237   \n",
       "33146    37108.0 -0.841910  0.427966  1.330937  0.301196  0.609865 -0.219677   \n",
       "264977  161676.0 -2.095268 -0.113154  0.839074 -1.434403 -0.665841 -0.353520   \n",
       "93587    64497.0 -3.141003 -0.036423  0.856031  1.320876 -1.720489  0.500438   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "49186   0.938138 -0.220247 -1.522497  ... -0.275536 -0.252815 -0.037271   \n",
       "148622  1.103789 -0.609933  1.116355  ... -0.377947 -0.514977  0.292790   \n",
       "33146   0.900994  0.060344 -0.531687  ...  0.083133  0.150999 -0.050524   \n",
       "264977 -0.428983  0.858931 -1.274300  ... -0.533818 -1.636550 -0.234419   \n",
       "93587  -0.410874  1.402324 -0.624236  ...  0.154052  0.234413  0.182089   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "49186  -0.433363 -0.534420  0.827410 -0.003107  0.143291  125.00      0  \n",
       "148622 -0.003732 -0.763451  0.112490 -0.148373 -0.079387    1.98      0  \n",
       "33146   0.013978  0.142768 -0.543907  0.092772  0.136472   77.00      0  \n",
       "264977 -0.722215  0.257054  0.001017 -0.303029 -0.230370   80.90      0  \n",
       "93587   0.037901  0.358644 -0.271475 -0.220354 -0.604723  141.09      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    492\n",
       "1    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_dataset.drop(columns='Class', axis=1)\n",
    "Y = new_dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time        V1        V2        V3        V4        V5        V6  \\\n",
      "49186    43950.0 -0.394463  0.036658  0.404250 -1.770945 -0.165441 -0.076140   \n",
      "148622   90083.0 -0.348459  0.641847  0.845793 -0.101879  0.890992 -1.039237   \n",
      "33146    37108.0 -0.841910  0.427966  1.330937  0.301196  0.609865 -0.219677   \n",
      "264977  161676.0 -2.095268 -0.113154  0.839074 -1.434403 -0.665841 -0.353520   \n",
      "93587    64497.0 -3.141003 -0.036423  0.856031  1.320876 -1.720489  0.500438   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
      "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
      "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
      "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
      "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
      "\n",
      "              V7        V8        V9  ...       V20       V21       V22  \\\n",
      "49186   0.938138 -0.220247 -1.522497  ... -0.446557 -0.275536 -0.252815   \n",
      "148622  1.103789 -0.609933  1.116355  ... -0.111132 -0.377947 -0.514977   \n",
      "33146   0.900994  0.060344 -0.531687  ...  0.089412  0.083133  0.150999   \n",
      "264977 -0.428983  0.858931 -1.274300  ... -0.628581 -0.533818 -1.636550   \n",
      "93587  -0.410874  1.402324 -0.624236  ... -0.396564  0.154052  0.234413   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "279863 -0.882850  0.697211 -2.064945  ...  1.252967  0.778584 -0.319189   \n",
      "280143 -1.413170  0.248525 -1.127396  ...  0.226138  0.370612  0.028234   \n",
      "280149 -2.234739  1.210158 -0.652250  ...  0.247968  0.751826  0.834108   \n",
      "281144 -2.208002  1.058733 -1.632333  ...  0.306271  0.583276 -0.269209   \n",
      "281674  0.223050 -0.068384  0.577829  ... -0.017652 -0.164350 -0.295135   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \n",
      "49186  -0.037271 -0.433363 -0.534420  0.827410 -0.003107  0.143291  125.00  \n",
      "148622  0.292790 -0.003732 -0.763451  0.112490 -0.148373 -0.079387    1.98  \n",
      "33146  -0.050524  0.013978  0.142768 -0.543907  0.092772  0.136472   77.00  \n",
      "264977 -0.234419 -0.722215  0.257054  0.001017 -0.303029 -0.230370   80.90  \n",
      "93587   0.182089  0.037901  0.358644 -0.271475 -0.220354 -0.604723  141.09  \n",
      "...          ...       ...       ...       ...       ...       ...     ...  \n",
      "279863  0.639419 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00  \n",
      "280143 -0.145640 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76  \n",
      "280149  0.190944  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89  \n",
      "281144 -0.456108 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00  \n",
      "281674 -0.072173 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53  \n",
      "\n",
      "[984 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49186     0\n",
      "148622    0\n",
      "33146     0\n",
      "264977    0\n",
      "93587     0\n",
      "         ..\n",
      "279863    1\n",
      "280143    1\n",
      "280149    1\n",
      "281144    1\n",
      "281674    1\n",
      "Name: Class, Length: 984, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(984, 30) (787, 30) (197, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training data :  0.9491740787801779\n"
     ]
    }
   ],
   "source": [
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "print('Accuracy on Training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on Test Data :  0.9238578680203046\n"
     ]
    }
   ],
   "source": [
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "print('Accuracy score on Test Data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################### PROGRAM STARTED #########################################################\n",
      "\n",
      "Array 0 = [107559    -26     15    -20      3      8      2     -6      3     -1\n",
      "    -18     12     -8      1     -9      1     -3    -24     -2      3\n",
      "      9     22     -3      4     -1     -4     -1      0     -2    500]\n",
      "Model predicts FRAUD =  [1]\n",
      "######################################################### PROGRAM FINISHED #########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "count=0\n",
    "array=[]\n",
    "predictionOutcome=[0]\n",
    "\n",
    "print(\"######################################################### PROGRAM STARTED #########################################################\")\n",
    "\n",
    "while predictionOutcome == [0]:\n",
    "    arr1=np.random.randint(406, 172021)\n",
    "    arr2=np.random.randint(-30.552380, 2.354755)\n",
    "    arr3=np.random.randint(-19.874677, 22.057729)\n",
    "    arr4=np.random.randint(-31.103685\t, 3.618108\t)\n",
    "    arr5=np.random.randint(-4.848504, 12.114672)\n",
    "    arr6=np.random.randint(-22.105532, 11.095089)\n",
    "    arr7=np.random.randint(-6.406267, 9.146401)\n",
    "    arr8=np.random.randint(-43.557242, 12.699095)\n",
    "    arr9=np.random.randint(-41.044261, 20.007208)\n",
    "    arr10=np.random.randint(-13.434066, 6.956877)\n",
    "    arr11=np.random.randint(-24.5882624372475, 10.9082169153181)\n",
    "    arr12=np.random.randint(12.01891318, 13.0189131816199)\n",
    "    arr13=np.random.randint(-18.6837146333443, 3.75364090600675)\n",
    "    arr14=np.random.randint(-3.12779501198771, 3.43177440040788)\n",
    "    arr15=np.random.randint(-19.2143254902614, 5.64983759827285)\n",
    "    arr16=np.random.randint(-4.49894467676621, 2.82738468160897)\n",
    "    arr17=np.random.randint(-14.1298545174931, 3.59251491764535)\n",
    "    arr18=np.random.randint(-25.1627993693248, 6.73938438478335)\n",
    "    arr19=np.random.randint(-9.49874592104677, 3.79031621184375)\n",
    "    arr20=np.random.randint(3.68190355226504, 5.2283417900513)\n",
    "    arr21=np.random.randint(-18.7950859859973, 11.0590042933942)\n",
    "    arr22=np.random.randint(-22.7976039055519, 27.2028391573154)\n",
    "    arr23=np.random.randint(-8.88701714094871, 8.36198519168435)\n",
    "    arr24=np.random.randint(-19.2543276173719, 8.22555470088129)\n",
    "    arr25=np.random.randint(-2.02802422921896, 1.25920333745715)\n",
    "    arr26=np.random.randint(-4.78160552206407, 3.00309742944611)\n",
    "    arr27=np.random.randint(-1.20343522771167, 2.7452606721766)\n",
    "    arr28=np.random.randint(-7.26348214633855, 3.05235768679424)\n",
    "    arr29=np.random.randint(-4.45592095900066, 2.77662664081462)\n",
    "    arr30=np.random.randint(0, 3684.62)\n",
    "    \n",
    "    array = np.concatenate(([arr1], [arr2], [arr3], [arr4], [arr5], [arr6],[arr7],[arr8],[arr9],[arr10],[arr11],[arr12],[arr13],[arr14],[arr15],[arr16],[arr17],[arr18],[arr19],[arr20],[arr21],[arr22],[arr23],[arr24],[arr25],[arr26],[arr27],[arr28],[arr29],[arr30]), axis=0)\n",
    "    \n",
    "    print(\"\\nArray %d =\" %count, array)\n",
    "    \n",
    "    predictionOutcome = model.predict([array])\n",
    "    \n",
    "    if predictionOutcome == 0:\n",
    "        print(\"Model predicts LEGIT = \", predictionOutcome)\n",
    "        print(\"###################################################################################################################################\")\n",
    "    else:\n",
    "        print(\"Model predicts FRAUD = \", predictionOutcome)\n",
    "    \n",
    "    count+=1\n",
    "else:\n",
    "    print(\"######################################################### PROGRAM FINISHED #########################################################\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa5fa69e30719954c2b09cac18597052108f40beda7980d5a858c66bde628773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
